\section{Exercise 1}

%\usepackage{indentfirst}
%\setlength{\parindent}{2em} 
\paragraph*{1}
I shorten the notation by using sin as a replacement for sin(x) and cos as a replacement for cos(x).
We use the binet formula to get the power of $A^n$.
We first estimate the eigenvectors, then concatenate them into matrix $P$ and use this matrix to compute the diagonal matrix $B$, which can be used to directly take the power for the matrix $A$. Afterwards we need to reverse the operations, which we had done on achieving $B$ to get $A^n$.
\begin{gather*}
A^n =
\left( \begin{array}{cc}
\cos & \sin \\
-\sin & \cos \\
\end{array} \right)^n , v = \left( \begin{array}{c} x_1\\x_2 \end{array} \right), ( A-\lambda I )v = 0
\\
\left( \begin{array}{cc}
\cos & \sin \\
- \sin & \cos 
\end{array}
\right) -
\left( \begin{array}{cc}
\lambda & 0 \\
0 & \lambda
\end{array} 
\right)
= \\
(\cos ^2 - \lambda) + \sin ^2 = 0 \\
\lambda _1 = \ii \sin + \cos \\
\lambda _2 = - \ii \sin + \cos
\end{gather*}
Now we achieved the eigenvalues, so we can estimate the eigenvectors.
The eigenvector $\lambda _1$
\begin{gather*}
\left( \begin{array}{cc}
\cos & \sin \\
- \sin & \cos \\
\end{array} 
\right)
-
\left( \begin{array}{cc}
\ii \sin + \cos & 0\\
0 & \ii \sin + \cos 
\end{array} 
\right)
=
\left( \begin{array}{c}
\ii \\
1 
\end{array}
\right)
\end{gather*}
Symmetrically the vector for $\lambda _2$ is:
\begin{gather*}
\left( \begin{array}{c}
-\ii \\
1
\end{array} \right)
\end{gather*}
The matrix $P$ is just a concatenation of $\lambda _1$ and $\lambda _2$.
\begin{equation}
P = \left( \begin{array}{cc}
\ii & -\ii \\
1 & 1
\end{array} \right)
\end{equation}
To calculate an diagonal matrix, we use the equation $B=P^{-1}AP$ to transform A into a diagonal matrix.
\begin{gather*}
P^{-1} = \dfrac{1}{\text{det}(P)} \text{adj}(P) =\\
\dfrac{1}{2\ii}
\left( \begin{array}{cc}
1 & \ii \\
-1 & \ii
\end{array}
\right)
= 
\left( \begin{array}{cc}
\dfrac{1}{2\ii} & \dfrac{1}{2} \\
- \dfrac{1}{2\ii} & \dfrac{1}{2}
\end{array}
\
\right)
\\
P^{-1}AP =
\left( \begin{array}{cc}
\dfrac{1}{2\ii} & \dfrac{1}{2} \\
- \dfrac{1}{2\ii} & \dfrac{1}{2}
\end{array}
\right)
\left( \begin{array}{cc}
\cos & \sin \\
-\sin & \cos
\end{array}
\right)
\left( \begin{array}{cc}
\ii & -\ii \\
1 & 1
\end{array}
\right)
=\\
\left( \begin{array}{cc}
\left( \dfrac{cos}{2\ii} - \dfrac{\sin}{2} \right)\ii + \dfrac{\sin}{2 \ii} + \dfrac{\cos}{2} &
\left( \dfrac{cos}{2 \ii} - \dfrac{\sin}{2} \right)(-\ii) + \dfrac{\sin}{2 \ii}+\dfrac{\cos}{2} \\
\left( - \dfrac{\cos}{2 \ii} - \dfrac{\sin}{2} \right)\ii + -\dfrac{\sin}{2 \ii} + \dfrac{\cos}{2} &
\left( - \dfrac{\cos}{2 \ii} - \dfrac{\sin}{2} \right)(-\ii) - \dfrac{\sin}{2 \ii} + \dfrac{\cos}{2}
\end{array}
\right)
=\\
\left( \begin{array}{cc}
\cos - \ii \sin & 0\\
 0 & \cos + \ii \sin 
\end{array}
\right)
\end{gather*}
Now we can apply the power operation on the matrix.
\begin{equation*}
B^n = \left( \begin{array}{cc}
(\cos - \ii \sin)^n & 0\\
 0 & (\cos + \ii \sin )^n
\end{array}
\right)
\end{equation*}
Now we can apply the matrix exponential onto $A$, since $A = PB^{n}P^{-1}$.
\begin{gather*}
\left( \begin{array}{cc}
\ii & - \ii \\
1 & 1
\end{array}
\right)
\left( \begin{array}{cc}
(\cos - \sin \ii)^n & 0 \\
0 & (\cos + (\ii \sin )^n
\end{array}
\right)
\left( \begin{array}{cc}
\dfrac{1}{2\ii} & \dfrac{1}{2} \\
-\dfrac{1}{2 \ii} & \dfrac{1}{2}
\end{array}
\right)
=\\
\left( \begin{array}{cc}
(\cos - \sin \ii)^n \ii & (\cos + \ii \sin)^n)(-\ii) \\
(\cos - \sin \ii)^n & (\cos + \ii \sin)^n 
\end{array}
\right)
\left( \begin{array}{cc}
\dfrac{1}{2\ii} & \dfrac{1}{2} \\
-\dfrac{1}{2 \ii} & \dfrac{1}{2}
\end{array}
\right)
=\\
\dfrac{1}{2}
\left( \begin{array}{cc}
\left( \cos - \sin \ii \right)^n + (\cos + \sin \ii )^n & (\cos - \sin)^n \ii - (\cos + \sin \ii)^n \ii \\ 
\ii (\cos + \sin)^n  - \ii (\cos - \sin \ii )^n & \left( \cos - \sin \ii \right)^n + (\cos + \sin \ii )^n 
\end{array}
\right)
=
A^n
\end{gather*}

\improvement{Das geht noch einfacher.}

\begin{gather}
A^n = 
\left( 
	\begin{array}{cc}
		\cos(n\cdot x) & \sin(n\cdot x)\\
		-\sin(n\cdot x) & \cos(n\cdot x)
	\end{array}
\right)
\end{gather}
\improvement[inline]{Es ist eine Drehmatrix welche sich eifach um den \textbf{n} fachen Winkel weiter dreht. }


\paragraph*{2}
Like in exercise 1 we begin by getting the eigenvalues and eigenvectors and the matrix $P$.
\begin{gather*}
A =\left( \begin{array}{cc}
1 & 1 \\ -1 & 1
\end{array} \right)
\text{Eigenvalues of } A:
\left( \begin{array}{cc}
1 - \lambda & 1 \\ 
-1 & 1 -\lambda 
\end{array} \right)
=
(1-\lambda)^2 + 1 = 0\\
\lambda _1 = 1 +\ii \\
\lambda _2 = 1 -\ii \\
\text{Eigenvector of }\lambda _1, \lambda _2
\left[
\left( \begin{array}{cc}
1 & 1 \\
-1 & 1
\end{array} \right) 
-
\left( \begin{array}{cc}
1+\ii & 0\\
0 & 1+\ii
\end{array} \right)
\right]
\left( \begin{array}{c}
x_1 \\ x_2
\end{array} \right)
= 0 \\
v_1 =
\left( \begin{array}{c}
1 \ii
\end{array} \right)
\\
v_2 =
\left( \begin{array}{c}
1 \\ -\ii
\end{array} \right)
\end{gather*}
Since we computed the eigenvectors $v_1$ and $v_2$, we continue by calculating the diagonal matrix $B$.
\begin{gather*}
P =
\left( \begin{array}{cc}
1 & 1\\
\ii & -\ii
\end{array} \right) 
\Rightarrow P^{-1} = \dfrac{1}{\text{det}(P)}
\left( \begin{array}{cc}
-\ii & -1 \\
-\ii & 1
\end{array} \right) =  \dfrac{1}{-2 \ii}
\left( \begin{array}{cc}
-\ii & -1 \\
-\ii & 1
\end{array} \right) = 
\left( \begin{array}{cc}
\dfrac{1}{2} & \dfrac{1}{2\ii}\\
\dfrac{1}{2} & -\dfrac{1}{2\ii}
\end{array} \right)\\
B=
\left( \begin{array}{cc}
\dfrac{1}{2} & \dfrac{1}{2\ii}\\
\dfrac{1}{2} & -\dfrac{1}{2\ii}
\end{array} \right)
\left( \begin{array}{cc}
1 & 1\\
-1 & 1
\end{array} \right)
\left( \begin{array}{cc}
1 & 1\\
\ii & -\ii
\end{array} \right)
=
\left( \begin{array}{cc}
\dfrac{1}{2} & \dfrac{1}{2\ii}\\
\dfrac{1}{2} & -\dfrac{1}{2\ii}
\end{array} \right)
\left( \begin{array}{cc}
1+\ii & 1-\ii \\
-1+\ii & -1-\ii
\end{array} \right) 
=
\left( \begin{array}{cc}
1+\ii & 0\\
0 & 1-\ii
\end{array} \right)
\\
B^n =
\left( \begin{array}{cc}
(1+\ii)^n & 0\\
0 & (1-\ii)^n
\end{array} \right)
\\
A^n=PB^{n}P^{-1} =
\left( \begin{array}{cc}
1 & 1 \\
\ii & -\ii
\end{array} \right)
\left( \begin{array}{cc}
(1+\ii)^n & 0\\
0 & (1-\ii)^n
\end{array} \right)
\left( \begin{array}{cc}
\dfrac{1}{2} & \dfrac{1}{2\ii}\\
\dfrac{1}{2} & -\dfrac{1}{2\ii}
\end{array} \right) 
=
\left( \begin{array}{cc}
1 & 1 \\
\ii & -\ii
\end{array} \right)
\left( \begin{array}{cc}
\dfrac{(1+\ii)^n}{2} & \dfrac{(1+\ii)^n}{2\ii} \\
\dfrac{(1-\ii)^n}{2} & -\dfrac{(1-\ii)^n}{2\ii}
\end{array} \right)
=\\
\dfrac{1}{2}
\left( \begin{array}{cc}
(1+\ii)^n +(1-\ii)^n & (1+\ii)^n - (1-\ii)^n \\
\ii (1+\ii)^n - \ii (1-\ii)^n & (1+\ii)^n + (1-\ii)^n
\end{array} \right) = A^n
\end{gather*}


\section{Exercise 2}

\paragraph*{1}
Computing $A^{-1}B$.
\begin{gather*} 
A^{-1} = \frac{1}{\text{det}(A)}
\left( \begin{array}{ccc}
4 & 5 & 0 \\
2 & 3 & 1 \\
2 & 7 & -3 \\
\end{array} \right)
=
- \frac{1}{24} 
\left( \begin{array}{ccc}
-16 & 15 & 5 \\
8 & -12 & -4 \\
8 & -18 & 2 \\
\end{array} \right)
\\
AB = 
\frac{1}{12} \left( \begin{array}{cccc}
12 & 0 & -30 & 95 \\
0 & 12 & 24 & -52 \\
0 & 0 & 0 & -46 
\end{array} \right)
\end{gather*}
\paragraph*{2}
Computing $CA^{-1}$
\begin{gather*}
CA^{-1} =
\left( \begin{array}{ccc}
4 & 5 & 0 \\
2 & 3 & 1\\
2 & 7 & 9\\
-2 & 3 & 7\\
\end{array} \right)
( -\frac{1}{24})
\left( \begin{array}{ccc}
-16 & 15 & 5 \\
8 & -12 & -4 \\
8 & -18 & 2 \\
\end{array} \right)
=
\frac{1}{3}
\left( \begin{array}{ccc}
3 & 0 & 0\\
0 & 3 & 0\\
-12 & 27 & 0\\
-14 & 24 & 1\\
\end{array} \right)
\end{gather*}

\section{Exercise 3}
We want to proof the following equation:
\begin{equation}
\label{ex3}
\adj (AB) = \adj (B) \adj (A)
\end{equation}
It is already known that $A \adj (A) = \deter (A) I$, so
\begin{equation}
\label{adjA}
\adj (A) = A^{-1} \deter (A) I
\end{equation} 
Also it is known that 
\begin{equation}
\label{detmul}
\deter (AB) = \deter(A) \deter(B)
\end{equation}
We substitute \ref{adjA} into \ref{ex3}, by using \ref{detmul}.
\begin{gather*}
\adj (B) \adj (A) = \deter (B) B^{-1} I \deter (A) A^{-1} I = \\
\deter (A) \deter (B) B^{-1} I A^{-1} I = \deter (AB) (AB)^{-1}
\end{gather*}
Using $C=AB$ we get:
\begin{gather*}
\deter(C) C^{-1} = \adj (C) \Rightarrow \adj (AB) = \adj (A) \adj (B)
\end{gather*}

\section{Exercise 4}
Assuming having a matrix $A$ with dimensions of $n\times m$.\\
We assume that there exists two ranks, rowrank(A) and colrank(A).
\begin{gather*}
A = \left( \begin{array}{ccc}
a_{11} & \hdots & a_{n1} \\
\vdots & \ddots & \vdots \\
a_{1m} & \hdots & a_{nm}
\end{array} \right)
\end{gather*}
If we modify $A$ to $A^{'}$ by doing Gaussian elimination, $A^{'}$ will have exactly $r$ non-zero rows, which will be denoted as $\text{rowrank}(A) = r$. 
By doing the transpose $A^{{'}^T}$, we can still observe that the rowrank is $r$ times non-zero rows. Since the columns in the transpose are the rows of the non-transpose, it leads to:
\begin{equation*}
\text{rowrank}(A^{'}) = \text{rowrank}(A^{{'}^T}) = \text{colrank}(A^{'}) = \text{colrank}(A^{{'}^T}) = \text{rowrank}(A) = \text{colrank} (A)
\end{equation*}

I show that this behaviour is working as well for the square $AA^T$ matrix. Since it is already proofed that the column rank is the row rank, we can use the basic formula for ranks :$\rank(AB) \leq \min(\rank (A), \rank(B))$.
\begin{equation}
\rank(A A^T) \leq \min( \rank (A) , \rank (A^T)) \Rightarrow \rank (A)=\rank (A^T)= \rank (A A^T)
\end{equation}

\section{Exercise 5}
To proof $\rank (A^n) = \rank (A^{n+1})$  we use recursion. 
\begin{equation}
\label{rankeq}
\rank (AB) \leq \min (\rank (A), \rank (B))
\end{equation}
By the use of \ref{rankeq} we get the following recursion:
\begin{gather*}
\rank (A^{n+1}) = \\ 
\rank (A^{n} A) \leq \min ( \rank (A^n), \rank(A) ) \\
\rank (A^n) = \rank (A^{n-1} A) \leq \min ( \rank (A^{n-1}), \rank(A) ) \\
\vdots \\
\rank(A A) = \min ( \rank (A), \rank(A) ) = \rank(A)
\end{gather*}
So after this recursion, it can be seen that $\rank (A^{n+1)}) = \rank (A^{n})$